{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import random\n",
    "from matplotlib import animation\n",
    "import matplotlib.animation as animation\n",
    "%matplotlib notebook\n",
    "np.set_printoptions(precision=3)\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GIBBS SAMPLING IN CONDITIONAL RANDOM FIELDS\n",
    "### Loic Landrieu, 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider an image $I$ whose structure is given by the graph $(V,E)$ where $V$ is the set of pixels and $E \\subset V \\times V$ encodes their adjacency (4 pixel adjacency - up, down, left right).\n",
    "\n",
    "We want to retrieve a binary latent variable $Z \\rightarrow \\{0,1\\}^V$ for each pixel. We have an observation $x \\in \\mathbb{\\Omega}^V$ with $\\Omega \\subset \\mathbb{R}^d$, related to the unobserved latent variable. However, we also know that the latent variable is spatially regular over the image.\n",
    "\n",
    "To implement this prior, we model the random variable $Z$ as a conditional random field (CRF), which is a discriminative undirected graphical model.\n",
    "\n",
    "<img src=\"CRF.png\" alt=\"CRF\" style=\"width: 200px;\"/>\n",
    "\n",
    "This model can be described by an Ising model:\n",
    "$$\n",
    "p(z \\mid x ; \\eta) = \\exp\\left(\\sum_{i \\in V} \\eta_{i}z_i + \\sum_{(i,j) \\in E} \\eta_{i,j}z_i z_j\\right)~,\n",
    "$$\n",
    "with $\\eta$ defined as:\n",
    "\n",
    "$$\n",
    "\\eta_{i,j} = 4 \\lambda,\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\eta_i = \\log\\left( \\frac{{q}_i}{1-{q}_i} \\right) - 2 \\lambda \\mid N_i \\mid,\n",
    "$$\n",
    "where $N_i$ denotes the set of pixel neighboring $i$, $\\lambda\\in\\mathbb{R}$ is the regularization strength, and $q_i = p(z_i=1 \\mid x_i)$.\n",
    "\n",
    "In practice , we regularize $q$ to prevent numerical issues\n",
    "$$\n",
    "\\hat{q_i} = (1-\\alpha) q_i + \\frac\\alpha2\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1: Complete the following function which takes as input an array $\\left( \\pi_i \\right)_{i \\in V}$  of probabilities : $\\pi_i = p(Y_i=1)$ for an unspecified random variable $Y$, and a regularizing parameter $\\alpha$ and returns the array $\\left(\\hat{\\pi}_i \\right)_{i \\in V}$\n",
    "with $\\hat{\\pi}_i = (1-\\alpha) \\pi_i + \\frac\\alpha2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularize(pis, alpha):\n",
    "    return #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2 In pratical applications probabilities $q_i$ are computed from the observations by another model. Here set them by hand in the cell below.\n",
    "\n",
    "\n",
    "What can we expect the marginals $p(z_i = 1\\mid x)$ to be like if $\\lambda$ is high? Low? Extremely high?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba = 0.5*np.random.rand(8,8)\n",
    "proba[0:2,:] = 0\n",
    "proba[-2:,:] = 1\n",
    "plt.figure()\n",
    "plt.imshow(proba)\n",
    "plt.set_cmap('binary')\n",
    "plt.title('Observation probability')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3: complete the following function to compute the unary potentials $\\eta_i$. Use a regularization term $\\alpha=0.05$.\n",
    "\n",
    "Visualize the image of unaries and make sure it makes sense. How can the first and last two rows have identical conditonals but not uniform unaries?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_unary(proba, reg_strength):\n",
    "    n_lin = proba.shape[0]\n",
    "    n_col = proba.shape[1]\n",
    "    n_nei = np.zeros((n_lin,n_col))\n",
    "    unary = np.zeros((n_lin,n_col))\n",
    "    \n",
    "    #count the neighbours\n",
    "    n_nei[1:,:] += 1\n",
    "    n_nei[:-1,:] += 1\n",
    "    n_nei[:,1:] += 1\n",
    "    n_nei[:,:-1] += 1\n",
    "\n",
    "    smoothed_proba = #TODO: regularized version of proba\n",
    "\n",
    "    return #TODO eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba = 0.5*np.random.rand((8,8))\n",
    "proba[0:2,:] = 0\n",
    "proba[-2:,:] = 1\n",
    "plt.figure()\n",
    "plt.imshow(proba)\n",
    "plt.set_cmap('binary')\n",
    "plt.title('Observation probability')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the Gibbs sampling algorithm to compute the pixel marginals of $X$ : $p(z_{i}=1\\mid x;\\eta)$.\n",
    "\n",
    "$z^{(0)} \\leftarrow \\;\\texttt{random initialization}$\n",
    "\n",
    "$\\texttt{for t = 1 to max_ite_gibbs:}$\n",
    "\n",
    "$\\quad i\\leftarrow \\texttt{random pixel}$\n",
    "    \n",
    "$\\quad \\texttt{sample}\\; z^{(t)}_i\\; \\texttt{from}\\; p(z_{i}\\mid z^{(t-1)},x;\\eta)$\n",
    "\n",
    "$\\quad z_{i}^{(t)} \\leftarrow  z_{i}^{(t-1)}$\n",
    "\n",
    "After enough iteration, we have:\n",
    "\n",
    "$$p(z_{i}=1\\mid x;\\eta) \\approx \\frac1{T-T_0}\\sum_{t = T_0+1}^T z_{i}^{(t)}.$$\n",
    "\n",
    "Note: in the Ising model, we have:\n",
    "\n",
    "$$\n",
    "p(z_{i}\\mid z^{(t-1)},x;\\eta) = \\frac1{\\exp\\left(-\\eta_i - \\sum_{j \\sim i} \\eta_{i,j} x_j\\right)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4: Complete the following function to compute the interaction term $ \\sum_{j \\sim i} \\eta_{i,j} x_j$ for all pixels. Visualize the results for a current sample $z^{(t)}$ taken at $1$ where $p(z_i^{(t)}\\mid x_i)\\geq0.5$. Make sure you understand the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_interaction(current, reg_strength):\n",
    "    n_lin = current.shape[0]\n",
    "    n_col = current.shape[1]\n",
    "    #compute a padded version of current with extra zero values on the borders for efficient computation of the sum of x_j\n",
    "    padded_current = np.zeros((n_lin+2,n_col+2))\n",
    "    padded_current[1:-1,1:-1]= current\n",
    "    sum_of_neighbors_x = (padded_current[0:-2,1:-1] + padded_current[2:,1:-1] + padded_current[1:-1,0:-2] + padded_current[1:-1,2:])\n",
    "    return #TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.subplot(121)\n",
    "plt.title('current')\n",
    "plt.imshow(proba>=0.5)\n",
    "plt.subplot(122)\n",
    "plt.title('interaction')\n",
    "plt.imshow(compute_interaction(proba>=0.5, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5: complete the following function to compute one update step of Gibbs sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_gibbs_update(unary, current, interaction, reg_strength):\n",
    "    n_lin = unary.shape[0]\n",
    "    n_col = unary.shape[1]\n",
    "    \n",
    "    i_lin = np.random.randint(n_lin)\n",
    "    i_col = np.random.randint(n_col)\n",
    "\n",
    "    proba_conditional = #TODO\n",
    "\n",
    "    new_value = np.random.rand()< proba_conditional\n",
    "    \n",
    "    #since we only changed the value of one pixel, we can only update the interatcion teerm of its neighbors \n",
    "    diff = new_value - current[i_lin, i_col]\n",
    "    current[i_lin, i_col] = new_value\n",
    "\n",
    "    if i_lin > 0 : interaction[i_lin-1, i_col] += #TODO\n",
    "    if i_lin < n_lin - 1 : interaction[i_lin+1, i_col] += #TODO\n",
    "    if i_col > 0 : interaction[i_lin, i_col-1] += #TODO\n",
    "    if i_col < n_col - 1 : interaction[i_lin, i_col+1] += #TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test cell, run it a few times to make sure it doesn't crash\n",
    "\n",
    "unary = compute_unary(proba, 0.5)\n",
    "current = (np.random.randint(2, size = proba.shape)).astype('f4')\n",
    "interaction = compute_interaction(current, 0.5)\n",
    "for i in range(100):\n",
    "    one_gibbs_update(unary, current, interaction, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6: Complete the following function, which performs Gibbs sampling, keep track of the samples $\\sum_{t = T_0+1}^T z_{i}^{(t)}$ and represent the marginals every $100$ iterations. Chose a burn in period of $10\\%$ of the iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def animate_gibbs_simple(proba, n_ite_gibbs = 1000, reg_strength = 0.5):\n",
    "    \n",
    "    n_lin = proba.shape[0]\n",
    "    n_col = proba.shape[1]\n",
    "    burn_in = #TODO\n",
    "\n",
    "    global sample_history, current, interaction\n",
    "    current = (np.random.randint(2, size = proba.shape)).astype('f4')\n",
    "    unary = #TODO\n",
    "    interaction = #TODO\n",
    "    sample_history = np.zeros_like(proba)\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    plt.title(\"Burn in\") \n",
    "    plt.axis('off')\n",
    "    plt.set_cmap('binary')\n",
    "    im = plt.imshow(sample_history, animated=True, vmin = 0, vmax = 1)\n",
    "\n",
    "    def updatefig(i):\n",
    "        #i is the iteration\n",
    "        global sample_history, current, interaction\n",
    "        one_gibbs_update(unary, current, interaction, reg_strength)  \n",
    "        \n",
    "        if i > burn_in :\n",
    "            sample_history = #TODO\n",
    "\n",
    "        if i > burn_in and i % 100 == 0 :\n",
    "            plt.title(\"Iteration = %d\" % (i))\n",
    "            im.set_array(sample_history/(i-burn_in+1))\n",
    "        \n",
    "        return im,\n",
    "    \n",
    "    anim = animation.FuncAnimation(fig, updatefig, interval=1, blit=True, frames = n_ite_gibbs, repeat = False)\n",
    "    plt.show()\n",
    "    return anim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7: run the following cell a few times. What do you notice from one run to another? Was this expected?\n",
    "\n",
    "Comment on the convergence speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "p = animate_gibbs_simple(proba, reg_strength = 1, n_ite_gibbs = 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8: We consider a binary checker-like partition of the grid into black $B$ and whites $W$ tiles of a chess board, as represented below. Show that \n",
    "$$\n",
    "p(z_B \\mid z^{(t-1)}, x; \\eta) =  p(z_B \\mid z_W^{(t-1)}, x; \\eta),\n",
    "$$\n",
    "\n",
    "and symetrically\n",
    "\n",
    "$$\n",
    "p(z_W \\mid z^{(t-1)}, x; \\eta) =  p(z_W \\mid z_B^{(t-1)}, x; \\eta).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.set_cmap('binary')\n",
    "coords=np.ogrid[0:8,0:8]\n",
    "selected_pixel=(coords[0]+coords[1])%2 == 0\n",
    "plt.imshow(selected_pixel)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9 : As a consequence we can modify the Gibbs algorithm to alternate between sampling all white and black tiles. Complete the follwoing function to implement this. Justify why this should be faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block_gibbs_update(even_ite, unary, current, interaction, reg_strength):\n",
    "    n_lin = unary.shape[0]\n",
    "    n_col = unary.shape[1]\n",
    "    \n",
    "    coords=np.ogrid[0:n_lin,0:n_col]\n",
    "    selected_pixel=(coords[0]+coords[1])%2 == even_ite\n",
    "\n",
    "    proba_conditional = #TODO - proba_conditional for all selected pixels\n",
    "    new_value = np.random.rand(proba_emission.size)< proba_conditional\n",
    "    current[selected_pixel] = new_value\n",
    "    interaction[:,:] = compute_interaction(current, reg_strength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test cell, run it a few times to make sure it doesn't crash\n",
    "\n",
    "unary = compute_unary(proba, 0.5)\n",
    "current = (np.random.randint(2, size = proba.shape)).astype('f4')\n",
    "interaction = compute_interaction(current, 0.5)\n",
    "for i in range(100):\n",
    "    block_gibbs_update(i%2, unary, current, interaction, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def animate_gibbs_block(proba, n_ite_gibbs = 1000, reg_strength = 0.1, temperature = 1):  \n",
    "   #TODO. Same as animate_gibbs_simple but with block sampling\n",
    "    return anim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9 : Run Block Gibbs sampling on this larger exemple. It should be much faster.\n",
    "\n",
    "Try the following value for reg strength and comment:\n",
    "$$0,0.2,0.5,1,10,-1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba = 0.5*np.random.rand((100,100))\n",
    "proba[0:2,:] = 0\n",
    "proba[-2:,:] = 1\n",
    "animate_gibbs_block(proba, n_ite_gibbs = 2000, reg_strength = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q10: We now consider an application to object/background image segmentation. This time the probability comes from a discriminative learning algorithm (random forrest) trained on the RGB values of an image coupled with its ground truth segmentation. The trained algorithm gives for each pixel of a test image a probability score of being in state object/background. Run the following cells to represent this probability, and comment on the resulting probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fish_train_rgb = np.asarray(Image.open(\"fish1.jpg\").convert('RGB'))\n",
    "fish_train_tag_rgb = np.asarray(Image.open(\"fish1Tag.jpg\").convert('RGB'))\n",
    "fish_train_gt = ((fish_1_tag_rgb).sum(-1) > 200) #white enough\n",
    "fish_test_rgb = np.asarray(Image.open(\"fish3.jpeg\").convert('RGB'))\n",
    "\n",
    "fish_train_vec = fish_train_rgb.reshape(-1, fish1_rgb.shape[-1])\n",
    "fish_test_vec = fish_test_rgb.reshape(-1, fish2_rgb.shape[-1])\n",
    "fish_train_vec_gt = fish1_gt.flatten()\n",
    "fish_train_dim = fish_train_rgb.shape[0:2]\n",
    "fish_test_dim = fish_test_rgb.shape[0:2]\n",
    "\n",
    "figure(num=None, figsize=(12, 5), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.subplot(131)\n",
    "plt.axis('off')\n",
    "imshow(fish_train_rgb)\n",
    "plt.title('train image')\n",
    "plt.subplot(132)\n",
    "plt.axis('off')\n",
    "plt.title('ground truth')\n",
    "imshow(fish_train_gt)\n",
    "plt.subplot(133)\n",
    "plt.axis('off')\n",
    "plt.title('test image')\n",
    "imshow(fish_test_rgb)\n",
    "\n",
    "rfe = RandomForestClassifier(max_depth=None, min_samples_split=2, random_state=0, n_estimators = 10)\n",
    "rfe.fit(fish_train_vec, fish_train_vec_gt)\n",
    "fish_proba = rfe.predict_proba(fish_test_vec)[:,1]\n",
    "fish_proba = fish_proba.reshape((fish_test_dim))\n",
    "figure(num=None, figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.subplot(121)\n",
    "plt.axis('off')\n",
    "plt.title('probability')\n",
    "imshow(fish_proba)\n",
    "plt.subplot(122)\n",
    "plt.axis('off')\n",
    "plt.title('thresholded at 0.5')\n",
    "imshow(fish_proba>0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q11: Run Block gibbs sampling on the object probability given by the random forrest. Find an appropriate regularization strength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that Gibbs sampling is NOT an efficient method of object segmentation. This exercice is an illustration of the method.\n",
    "Object segmentation amounts to compute the MAP of this problem, which can be efficienctly computed using max-flow formulations as long as the interactions are attractives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
